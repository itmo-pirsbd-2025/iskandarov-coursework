# Стриминг Крипто Аналитика

## Общее описание проекта

Данный проект — учебный прототип системы крипто-аналитики, реализуемый в рамках дисциплины **"Потоковый анализ данных"**

В рамках проекта требуется сделать следующее:

- Найти источник потоковых данных или реализовать генератор;
- Развернуть кластер Apache Kafka. Написать ETL, который должен получать данные от источников и сохранять предобработанные данные в топики с учетом требований по семантикам, надежности и быстродействи;
- Развернуть Apache Flink. Настроить чтение из топиков Kafka. Реализовать необходимые конвейеры для обработки потоков данных;
- Создать потоковое API, создать потокового клиента. Выбрать паттерны и протоколы их взаимодействия. Клиент – веб или мобильное приложение для конечного пользователя.

## Описание данных
Мы будем получать данных при помощи Binace API, работающем на Stream Websocket

Базовая конечная точка для API:

```wss://stream.binance.com:9443 or wss://stream.binance.com:443```

Входные данные это котировки криптовалюты. 
[Более подробное описание из API:](https://developers.binance.com/docs/binance-spot-api-docs/web-socket-streams#klinecandlestick-streams-for-utc)

```
Stream Name: <symbol>@kline_<interval>

Update Speed: 1000ms for 1s, 2000ms for the other intervals

Payload:

{
    "e": "kline",               // Event type
    "E": 1672515782136,         // Event time
    "s": "BNBBTC",              // Symbol
    "k": {
        "t": 1672515780000,     // Kline start time
        "T": 1672515839999,     // Kline close time
        "s": "BNBBTC",          // Symbol
        "i": "1m",              // Interval
        "f": 100,               // First trade ID
        "L": 200,               // Last trade ID
        "o": "0.0010",          // Open price
        "c": "0.0020",          // Close price
        "h": "0.0025",          // High price
        "l": "0.0015",          // Low price
        "v": "1000",            // Base asset volume
        "n": 100,               // Number of trades
        "x": false,             // Is this kline closed?
        "q": "1.0000",          // Quote asset volume
        "V": "500",             // Taker buy base asset volume
        "Q": "0.500",           // Taker buy quote asset volume
        "B": "123456"           // Ignore
    }
}
```

Выходные данные - скользящее среднее, вычисленное с помощью оконных функций по конкретной криптовалюте. Такой подход позволит увидеть тренды в изменении цен за последние минуты, что полезно для prediction-аналитики

## Ответы на вопросы
1.	Какие данные для этой области являются потоковыми?

Данные о котировках криптовалют

2.	Какие результаты мы хотим получить в результате обработки?

Скользящее среднее цены криптовалюты (можно использовать в prediction-аналитике)

3.	Как в процессе обработки можно задействовать машинное обучение?

Машинное обучение можно задействовать, например, для построения линии тренда в данных цены криптовалюты

4.	Как предметная область относится к запаздыванию обработки? Насколько это критично?

Задержка должна быть низкой (в идеале менее секунды), это обусловлено необходимостью принятия решений на основе самых актуальных данных с Binance

5.	Как предметная область относится к потере данных? Насколько это критично? Какую семантику (не менее одного раза, не более одного раза, ровно один раз) следует выбрать?

Для потоковой системы с финансовыми данными следует избегать потери данных или дубликатов при обработке. Мы можем использовать доставку Exactly-once, что означает, что все данные были получены один раз без дубликатов

То есть:
- Небольшие потери данных возможны: для построения скользящего среднего используется оконная функция, отсюда незначительные потери не окажут значимого влияния на результат

- Cтоит выбрать семантику Exactly-once, что означает, что данные получены один раз без дубликатов

## Обзор приложения

Для хранения данных используется брокер сообщений Kafka

Для потоковой обработки поступающих данных из Kafka используется Flink.

Схема работы приложения следующая:

1. Данные котировок криптовалюты с Binance при помощи протокола Websocket и с использованием Binance API поступают в реальном времени
   в топик Kafka crypto_kline_data
2. Данные из Kafka поступают в систему потоковой обработки на Flink, где проводится усреднение цены криптовалюты с помощью плавающего окна. Окно
   срабатывает каждые три секунды, новое окно появляется каждые 0.5 секунды (некий сдвиг окон во времени)
3. Обработанные данные из Flink поступают в новый топик Kafka crypto_data_aggregated (агрегированные данные)
4. Далее агрегированные данные из Kafka поступают в разработанный Websocket-сервер, к которому подключаются клиенты, и в браузере можно видеть в реальном времени график изменения котировок криптовалюты. Эти данные можно в последующем использовать для систем прогнозирования в машинном обучении

Для реализации описанной схемы работы были разработаны модули:
1. Модуль обработки начальных данных ProducerPython - класс KafkaProducer.py. Его задача стягивать начальные данные с Binance и заносить
   нужные нам данные в топик Kafka
2. Модуль потоковой обработки данных в главном модуле. В данном модуле мы определяем схемы наших данных для сериализации в Kafka и десериализации из Kafka.
   Flink в реальном времени обрабатывает поступающие начальные данные из Kafka, производит с ними операции (агрегирования, усреднения) и выдает результат, который записывается в новый топик Kafka
3. Модуль ClientServerApp отвечает за сбор агрегированных данных из топика Kafka с использованием WebSocket сервера (серверная часть) и отображение графика изменения агрегированных котировок криптовалюты за определенный период (например две минуты) в браузере (клиентская часть)
