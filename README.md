# Стриминг Крипто Аналитика

## Общее описание проекта

Данный проект — учебный прототип системы крипто-аналитики, реализованный в рамках дисциплины **"Потоковый анализ данных"**

В рамках проекта требуется сделать следующее:

- Найти источник потоковых данных или реализовать генератор;
- Развернуть кластер Apache Kafka. Написать ETL, который должен получать данные от источников и сохранять предобработанные данные в топики с учетом требований по семантикам, надежности и быстродействи;
- Развернуть Apache Flink. Настроить чтение из топиков Kafka. Реализовать необходимые конвейеры для обработки потоков данных;
- Создать потоковое API, создать потокового клиента. Выбрать паттерны и протоколы их взаимодействия. Клиент – веб или мобильное приложение для конечного пользователя.

## Описание данных
Мы будем получать данных при помощи Binace API, работающем на Stream Websocket

Базовая конечная точка для API:

```wss://stream.binance.com:9443 or wss://stream.binance.com:443```

Входные данные это котировки криптовалюты

Выходные данные - скользящее среднее, вычисленное с помощью оконных функций по конкретной криптовалюте. Такой подход позволит увидеть тренды в изменении цен за последние минуты, что полезно для prediction-аналитики

## Ответы на вопросы
1.	Какие данные для этой области являются потоковыми?

Данные о котировках криптовалют

2.	Какие результаты мы хотим получить в результате обработки?

Скользящее среднее цены криптовалюты (можно использовать в prediction-аналитике)

3.	Как в процессе обработки можно задействовать машинное обучение?

Машинное обучение можно задействовать, например, для построения линии тренда в данных цены криптовалюты

4.	Как предметная область относится к запаздыванию обработки? Насколько это критично?

Задержка должна быть низкой (в идеале менее секунды) поскольку это необходимо для принятия решений на основе самых актуальных данных с биржи Binance

5.	Как предметная область относится к потере данных? Насколько это критично? Какую семантику (не менее одного раза, не более одного раза, ровно один раз) следует выбрать?

Для потоковой системы с финансовыми данными следует избегать потери данных или дубликатов при обработке. Мы можем использовать доставку Exactly-once, что означает, что все данные были получены один раз без дубликатов

То есть:
- Небольшие потери данных возможны: для построения скользящего среднего используется оконная функция, отсюда незначительные потери не окажут значимого влияния на результат

- Cтоит выбрать семантику Exactly-once, что означает, что данные получены один раз без дубликатов
